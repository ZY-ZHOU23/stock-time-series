---
title: "Stock Forecasting Project"
output: 
  pdf_document:
    toc: true
---

\newpage
# Libraries

```{r message=FALSE}
library(tidyverse)
library(lubridate)
library(quantmod)
library(tseries)
library(forecast)

library(tsibble)
library(fable)
library(fabletools)
library(feasts)

library(xgboost)
library(caret)

library(rugarch)
```

# Data Gathering

## User Inputs (Stock and Date)

```{r}
symbol <- "AAPL"
start_date <- as.Date("2020-01-01")
end_date <- Sys.Date()
```

## Stock Data Collection

```{r}
getSymbols(symbol, 
           src  = "yahoo", 
           from = start_date, 
           to   = end_date,
           auto.assign = TRUE)

stock_data <- get(symbol)

# head(stock_data)
```

# Data Exploration & Feature Engineering

## EDA

```{r}
# Convert time-series data (xts object) to a regular tibble
df_stock <- tibble(
  date     = zoo::index(stock_data),
  open     = as.numeric(stock_data[, paste0(symbol, ".Open")]),
  high     = as.numeric(stock_data[, paste0(symbol, ".High")]),
  low      = as.numeric(stock_data[, paste0(symbol, ".Low")]),
  close    = as.numeric(stock_data[, paste0(symbol, ".Close")]),
  volume   = as.numeric(stock_data[, paste0(symbol, ".Volume")]),
  adjusted = as.numeric(stock_data[, paste0(symbol, ".Adjusted")])
)

glimpse(df_stock)
summary(df_stock)

# Plot Adjusted Closing Price over time with a dynamic title
ggplot(df_stock, aes(x = date, y = adjusted)) +
  geom_line() +
  labs(title = paste(symbol, "Adjusted Closing Price"),
       x = "Date",
       y = "Adjusted Price") +
  theme_minimal()

```

```{r}
# Check if there is any NA (rare to have NA)
df_stock %>%
  summarize(across(everything(), ~ sum(is.na(.)))) 
```

## Feature Engineering

### Add new variables

```{r}
# Calculate Bollinger Bands using high, low, and close
bb <- BBands(HLC = df_stock %>% select(high, low, close),
             n = 20, maType = "SMA", sd = 2)

# Calculate MACD based on the adjusted closing price
macd_values <- MACD(df_stock$adjusted, nFast = 12, nSlow = 26, nSig = 9)

# Add all new variables
df_stock <- df_stock %>%
  arrange(date) %>%
  mutate(
    daily_return = (adjusted - lag(adjusted)) / lag(adjusted) * 100,
    lag1_close = lag(adjusted, 1),
    lag2_close = lag(adjusted, 2),
    ma20 = rollmean(adjusted, k = 20, fill = NA, align = "right"),
    ma50 = rollmean(adjusted, k = 50, fill = NA, align = "right"),
    rsi14 = RSI(adjusted, n = 14),
    bb_dn   = bb[, "dn"],
    bb_mavg = bb[, "mavg"],
    bb_up   = bb[, "up"],
    bb_pctB = bb[, "pctB"],
    macd    = macd_values[, "macd"],
    macdSig = macd_values[, "signal"],
    rolling_sd_20 = rollapply(daily_return, width = 20, 
                              FUN = sd, fill = NA, align = "right"),
    wday = wday(date, label = TRUE),
    sin_wday = sin(2 * pi * wday(date) / 7),
    cos_wday = cos(2 * pi * wday(date) / 7)
  )

```

### Visualize new variables

```{r warning=FALSE}
# 14-Day RSI
ggplot(df_stock, aes(x = date, y = rsi14)) +
  geom_line() +
  labs(title = "14-Day RSI", x = "Date", y = "RSI") +
  theme_minimal()

# MAs
df_stock_long <- df_stock %>%
  select(date, adjusted, ma20, ma50) %>%
  pivot_longer(cols = c("adjusted", "ma20", "ma50"), 
               names_to = "variable", values_to = "value")

ggplot(df_stock_long, aes(x = date, y = value, color = variable)) +
  geom_line() +
  labs(title = paste(symbol, "Adjusted Price vs MAs"),
       x = "Date", y = "Value", color = "Series") +
  theme_minimal()

# Bollinger Bands
ggplot(df_stock, aes(x = date)) +
  geom_line(aes(y = close), color = "blue") +
  geom_line(aes(y = bb_dn), color = "red", linetype = "dashed") +
  geom_line(aes(y = bb_up), color = "red", linetype = "dashed") +
  labs(title = "Bollinger Bands", y = "Price") +
  theme_minimal()

# 20-day Rolling Std Dev of Daily Returns
ggplot(df_stock, aes(x = date, y = rolling_sd_20)) +
  geom_line() +
  labs(title = "20-day Rolling Std Dev of Daily Returns",
       x = "Date", y = "Rolling SD (%)") +
  theme_minimal()
```

### Other tests and analysis
```{r}
# Correlation Matrix of Numeric Features
df_numerics <- df_stock %>%
  select(where(is.numeric)) %>%
  drop_na()  # Remove rows with NA for accurate correlation

GGally::ggcorr(df_numerics, 
               method = c("pairwise.complete.obs", "pearson"),
               label  = TRUE) +
  ggtitle("Correlation Matrix of Numeric Features")

```

```{r}
# Stationarity Tests: Adjusted Price and Daily Returns
adf_result <- adf.test(df_stock$adjusted, alternative = "stationary")
print(adf_result)

adf_returns <- adf.test(na.omit(df_stock$daily_return), alternative = "stationary")
print(adf_returns)

```

Findings on Stationarity: 
- The adjusted price is non-stationary, which is expected because stock prices tend to follow a random walk.
- The daily returns are stationary, which is typical for financial return series since they fluctuate around a constant mean.

```{r}
# difference
df_stock <- df_stock %>% 
  mutate(
    volume_diff = c(NA, diff(volume)),
    adjusted_diff = c(NA, diff(adjusted)),    
    ma20_diff = c(NA, diff(ma20)),
    ma50_diff = c(NA, diff(ma50)),
    rsi14_diff = c(NA, diff(rsi14)),
  )

checkresiduals(df_stock$adjusted_diff)
checkresiduals(df_stock$volume_diff)
checkresiduals(df_stock$rsi14_diff)
checkresiduals(df_stock$ma20_diff)
checkresiduals(df_stock$ma50_diff)
```

Based on the Ljung-Box test, `adjusted_diff` and `rsi14_diff` are stationary now. `volume_diff` is still non-stationary, but it is a lot better than the original `volume` variable.

# Model 1: ARIMA with Exogenous Regressors (ARIMAX)
## Preperation for model 1
### Convert to weekly data
```{r}
# Change to weekly data for less computation
df_weekly <- df_stock %>%
  mutate(week = floor_date(date, unit = "week", week_start = 1)) %>%
  group_by(week) %>%
  summarise(
    open = first(open),
    high = max(high, na.rm = TRUE),
    low = min(low, na.rm = TRUE),
    close = last(close),
    volume = sum(volume, na.rm = TRUE),
    first_adj = first(adjusted),                      
    adjusted = last(adjusted),                       
    weekly_return = (last(adjusted) / first_adj - 1) * 100,
    ma20 = last(ma20),
    ma50 = last(ma50),
    rsi14 = last(rsi14),
    bb_dn = last(bb_dn),
    bb_mavg = last(bb_mavg),
    bb_up = last(bb_up),
    bb_pctB = last(bb_pctB),
    macd = last(macd),
    macdSig = last(macdSig),
    rolling_sd_20 = last(rolling_sd_20),
    wday = last(wday),
    sin_wday = last(sin_wday),
    cos_wday = last(cos_wday),
    volume_diff = mean(volume_diff, na.rm = TRUE),
    adjusted_diff = mean(adjusted_diff, na.rm = TRUE),    
    ma20_diff = mean(ma20_diff, na.rm = TRUE),
    ma50_diff = mean(ma50_diff, na.rm = TRUE),
    rsi14_diff = mean(rsi14_diff, na.rm = TRUE),
  ) %>%
  ungroup() %>%
  select(-c(first_adj, wday))

head(df_weekly, 2)
```

### Train test split
```{r}
cutoff_date <- as.Date("2024-12-31")
begin_date <- as.Date("2023-03-01")

train_data <- df_weekly %>%
  filter(week >= begin_date & week <= cutoff_date) %>%
  drop_na(adjusted_diff, volume_diff, rsi14_diff, ma20_diff, ma50_diff)

test_data <- df_weekly %>%
  filter(week > cutoff_date) %>%
  drop_na(adjusted_diff, volume_diff, rsi14_diff, ma20_diff, ma50_diff)
```

### Forecast exogenous variables
```{r}
# Define a forecast function for a given variable (differenced)
forecast_exog <- function(train_df, test_df, var_name, freq = 52) {
  train_ts <- ts(train_df[[var_name]], frequency = freq)
  fit <- auto.arima(train_ts, stepwise = TRUE, approximation = TRUE)
  h <- nrow(test_df)
  fc <- forecast(fit, h = h)
  
  list(
    model_fit = fit,
    forecast_obj = fc,                     
    forecast = as.numeric(fc$mean),     
    AIC = AIC(fit),
    actual = ts(test_df[[var_name]], frequency = freq, 
                start = c(1, length(train_df[[var_name]]) + 1))
  )
}

# Define the differenced exogenous variables to forecast
exog_vars <- c("volume_diff", "rsi14_diff", "ma20_diff", "ma50_diff")
exog_perf <- tibble(variable = character(), 
                    MAPE = numeric(), 
                    MSE = numeric(), 
                    AIC = numeric())

exog_forecasts <- list()

for (var in exog_vars) {
  fc_result <- forecast_exog(train_data, test_data, var)
  exog_forecasts[[var]] <- fc_result$forecast
  
  # Compute performance metrics for this variable
  actual_ts <- fc_result$actual
  mape_exog <- mean(abs(fc_result$forecast - actual_ts) / abs(actual_ts)) * 100
  mse_exog <- mean((fc_result$forecast - actual_ts)^2)
  
  exog_perf <- exog_perf %>%
    add_row(variable = var, MAPE = mape_exog, MSE = mse_exog, AIC = fc_result$AIC)
  
  # Plot forecast vs. actual for this variable
  print(
    autoplot(fc_result$forecast_obj) +
      autolayer(actual_ts, series = "Actual") +
      labs(title = paste(symbol, var, "Forecast (Differenced)"),
           x = "Time", y = var) +
      theme_minimal()
  )
  
  print(fc_result$model_fit)
}

exog_perf
```

## Build model 1
```{r}
train_ts_diff <- ts(train_data$adjusted_diff, frequency = 52)
test_ts_diff  <- ts(test_data$adjusted_diff, frequency = 52, 
                     start = c(1, length(train_data$adjusted_diff) + 1))

xreg_train_diff <- as.matrix(train_data %>% 
                               select(volume_diff, rsi14_diff, 
                                      ma20_diff, ma50_diff))
xreg_test_diff  <- cbind(
  volume_diff = exog_forecasts[["volume_diff"]],
  rsi14_diff  = exog_forecasts[["rsi14_diff"]],
  ma20_diff   = exog_forecasts[["ma20_diff"]],
  ma50_diff   = exog_forecasts[["ma50_diff"]]
)

# Fit the ARIMAX model
model_arima_diff <- auto.arima(train_ts_diff, xreg = xreg_train_diff)
summary(model_arima_diff)

# Forecast
h <- nrow(test_data)
final_forecast_diff <- forecast(model_arima_diff, 
                                xreg = xreg_test_diff, h = h)
```

## Performance
```{r}
# convert forecast back to the original scale
last_train_level <- last(df_weekly %>% filter(week <= cutoff_date) %>% pull(adjusted))
recovered_forecast <- last_train_level + cumsum(final_forecast_diff$mean)
test_ts_levels <- ts(test_data$adjusted, frequency = 52, 
                      start = c(1, length(train_data$adjusted) + 1))

# Plot
autoplot(ts(recovered_forecast, frequency = 52, 
            start = c(1, length(train_data$adjusted) + 1))) +
  autolayer(test_ts_levels, series = "Actual") +
  labs(title = paste(symbol, "Recovered ARIMAX Forecast vs. Actual (Levels)"),
       x = "Time", y = "Adjusted Price") +
  theme_minimal()

# Error metrics
mape_final <- mean(abs(recovered_forecast - test_ts_levels) / abs(test_ts_levels)) * 100
mse_final <- mean((recovered_forecast - test_ts_levels)^2)
cat("Final Recovered ARIMAX Forecast -> MAPE:", mape_final, "\nMSE:", mse_final)

# Check residuals
checkresiduals(final_forecast_diff)
```

# Model 2: NNETAR with Exogenous Regressors
## Preparation for model 2
### Forecast exogenous variables
```{r}
forecast_exog <- function(train_df, test_df, var_name, freq = 52) {
  train_ts <- ts(train_df[[var_name]], frequency = freq)
  fit <- nnetar(train_ts)  # Use nnetar for forecasting
  h <- nrow(test_df)
  fc <- forecast(fit, h = h)
  
  list(
    forecast_obj = fc,
    forecast = as.numeric(fc$mean),
    AIC = NA,  # nnetar() does not provide AIC in the same way
    actual = ts(test_df[[var_name]], frequency = freq, 
                start = c(1, length(train_df[[var_name]]) + 1))
  )
}

# Define the differenced exogenous variables to forecast
exog_vars <- c("volume_diff", "rsi14_diff", "ma20_diff", "ma50_diff")
exog_perf <- tibble(variable = character(), 
                    MAPE = numeric(), 
                    MSE = numeric(), 
                    AIC = numeric())
exog_forecasts <- list()
h <- nrow(test_data)

for (var in exog_vars) {
  fc_result <- forecast_exog(train_data, test_data, var)
  exog_forecasts[[var]] <- fc_result$forecast
  
  # Compute performance metrics for each exogenous variable forecast
  actual_ts <- fc_result$actual
  mape_exog <- mean(abs(fc_result$forecast - actual_ts) / abs(actual_ts)) * 100
  mse_exog <- mean((fc_result$forecast - actual_ts)^2)
  
  exog_perf <- exog_perf %>%
    add_row(variable = var, MAPE = mape_exog, MSE = mse_exog, AIC = fc_result$AIC)
  
  # Plot forecast vs. actual for this exogenous variable
  print(
    autoplot(fc_result$forecast_obj) +
      autolayer(actual_ts, series = "Actual") +
      labs(title = paste(symbol, var, "Forecast (Differenced, NNETAR)"),
           x = "Time", y = var) +
      theme_minimal()
  )
}

exog_perf
```

## Build model 2
```{r}
train_tsibble_diff <- train_data %>% as_tsibble(index = week)

fit_nnet <- train_tsibble_diff %>%
  model(
    nnet = NNETAR(adjusted_diff ~ volume_diff + rsi14_diff + ma20_diff + ma50_diff)
  )

# forecast
test_exog_data <- test_data %>% 
  select(week) %>%
  mutate(
    volume_diff = exog_forecasts[["volume_diff"]],
    rsi14_diff  = exog_forecasts[["rsi14_diff"]],
    ma20_diff   = exog_forecasts[["ma20_diff"]],
    ma50_diff   = exog_forecasts[["ma50_diff"]]
  )
test_exog_tsibble <- as_tsibble(test_exog_data, index = week)

fc_nnet_diff <- fit_nnet %>% forecast(new_data = test_exog_tsibble)

```

## Performance
```{r}
last_train_level <- last(df_weekly %>% filter(week <= cutoff_date) %>% pull(adjusted))

# Convert the NNETAR differenced forecast to a tibble and order by week
fc_nnet_diff_df <- fc_nnet_diff %>% as_tibble() %>% arrange(week)

# Recover the level forecasts by cumulatively summing the forecasted differences onto last_train_level
recovered_forecast_nnet <- last_train_level + cumsum(fc_nnet_diff_df$.mean)

test_levels <- test_data$adjusted

# Build a data frame for plotting and evaluation
df_plot_nnet <- tibble(
  week = fc_nnet_diff_df$week,
  forecast = recovered_forecast_nnet,
  actual = test_levels
)

ggplot(df_plot_nnet, aes(x = week)) +
  geom_line(aes(y = actual), color = "black") +
  geom_line(aes(y = forecast), color = "blue") +
  labs(title = paste(symbol, 
                     "NNETAR Forecast (Recovered Levels) with Forecasted 
                     Exogenous (Differenced, NNETAR)"),
       x = "Date", y = "Adjusted Price") +
  theme_minimal()

# Compute error metrics on the original scale
mape_nnet <- mean(abs(df_plot_nnet$forecast - df_plot_nnet$actual) / abs(df_plot_nnet$actual)) * 100
mse_nnet  <- mean((df_plot_nnet$forecast - df_plot_nnet$actual)^2)
cat("NNETAR Recovered Forecast -> MAPE:", mape_nnet, "\nMSE:", mse_nnet)

```

# Model 3: Tree-Based Ensemble
## Preparation for model 3
### Helper function
```{r}
forecast_exog_xgb <- function(train_df, test_df, var_name, 
                              lags = 2, freq = 52, nrounds = 50, 
                              max_depth = 3, eta = 0.1) {
  require(xgboost)
  
  # Note: embed returns rows in reverse order; we reverse it back.
  x_train <- embed(train_df[[var_name]], lags + 1)
  x_train <- x_train[nrow(x_train):1, ]
  y_train <- x_train[, 1]
  X_train <- x_train[, -1, drop = FALSE]
  
  dtrain <- xgb.DMatrix(data = X_train, label = y_train)
  
  # Train XGBoost model for one-step forecast
  params <- list(
    objective = "reg:squarederror",
    eta = eta,
    max_depth = max_depth,
    subsample = 0.8,
    colsample_bytree = 0.8
  )
  
  model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = nrounds,
    verbose = 0
  )
  
  # Recursive forecast for h steps
  h_steps <- nrow(test_df)
  preds <- numeric(h_steps)
  # Get the last available 'lags' values from the training series (in chronological order)
  last_values <- tail(train_df[[var_name]], lags)
  for(i in 1:h_steps) {
    # For prediction, the features should be: most recent value as lag1, second most recent as lag2, etc.
    # Our model was trained with features: [lag1, lag2, ..., lag(lags)] where lag1 is the most recent.
    features <- matrix(rev(last_values), nrow = 1)  # reverse to get most recent first
    dtest <- xgb.DMatrix(data = features)
    pred <- predict(model, dtest)
    preds[i] <- pred
    # Update last_values: drop the oldest and append the new prediction
    last_values <- c(last_values[-1], pred)
  }
  
  list(
    forecast = preds,
    model_fit = model
  )
}

```

### Forecast exogenous variables
```{r}
exog_vars <- c("volume_diff", "rsi14_diff", "ma20_diff", "ma50_diff")
exog_perf <- tibble(variable = character(), MAPE = numeric(), MSE = numeric())
exog_forecasts <- list()

h <- nrow(test_data)

for (var in exog_vars) {
  fc_result <- forecast_exog_xgb(train_data, test_data, 
                                 var, lags = 2, freq = 52, 
                                 nrounds = 50, max_depth = 3, eta = 0.1)
  exog_forecasts[[var]] <- fc_result$forecast
  
  # Compute performance metrics on test data 
  actual <- test_data[[var]]
  mape_exog <- mean(abs(fc_result$forecast - actual) / abs(actual)) * 100
  mse_exog  <- mean((fc_result$forecast - actual)^2)
  
  exog_perf <- exog_perf %>%
    add_row(variable = var, MAPE = mape_exog, MSE = mse_exog)
  
  cat(paste("Exogenous variable:", var, " - MAPE:", round(mape_exog,2), "%, MSE:", round(mse_exog,2), "\n"))
}

exog_perf
```

## Build Model 3
```{r}
df_tree <- df_weekly %>%
  arrange(week) %>%
  mutate(
    lag1_adjusted = lag(adjusted, 1),
    lag2_adjusted = lag(adjusted, 2)
  ) %>%
  drop_na()

# Split df_tree using the same cutoff
train_tree <- df_tree %>% filter(week <= cutoff_date)
test_tree  <- df_tree %>% filter(week > cutoff_date)

# For training, we use observed exogenous values
X_train <- as.matrix(train_tree %>% select(lag1_adjusted, lag2_adjusted, volume, rsi14, ma20, ma50))
y_train <- train_tree$adjusted

# For testing, use the observed lag features from test_tree,
# but replace the current exogenous values with forecasted ones.
X_test <- as.matrix(test_tree %>% select(lag1_adjusted, lag2_adjusted))
# Append forecasted exogenous variables (for test period) from our exog_forecasts.
# Ensure the forecasted vectors have length equal to nrow(test_tree)
X_test <- cbind(
  X_test,
  volume = exog_forecasts[["volume_diff"]],   # Note: if you prefer to use levels, you might forecast the level and not the diff.
  rsi14  = exog_forecasts[["rsi14_diff"]],
  ma20   = exog_forecasts[["ma20_diff"]],
  ma50   = exog_forecasts[["ma50_diff"]]
)

# Create DMatrix objects for XGBoost
dtrain <- xgb.DMatrix(data = X_train, label = y_train)
dtest  <- xgb.DMatrix(data = X_test, label = test_tree$adjusted)

# Set parameters for final XGBoost model
params <- list(
  objective = "reg:squarederror",
  eval_metric = "rmse",
  eta = 0.1,
  max_depth = 6,
  subsample = 0.8,
  colsample_bytree = 0.8
)

set.seed(123)
model_xgb <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 10,
  verbose = 0
)

pred_xgb <- predict(model_xgb, dtest)

```

## Performance
```{r}
mape_tree <- mean(abs(pred_xgb - test_tree$adjusted) / abs(test_tree$adjusted)) * 100
mse_tree  <- mean((pred_xgb - test_tree$adjusted)^2)
cat("Final XGBoost Model -> MAPE:", round(mape_tree,2), "%, MSE:", round(mse_tree,2), "\n")

# Plot actual vs. forecasted adjusted prices
df_plot_tree <- tibble(
  week = test_tree$week,
  actual = test_tree$adjusted,
  forecast = pred_xgb
)

ggplot(df_plot_tree, aes(x = week)) +
  geom_line(aes(y = actual), color = "black") +
  geom_line(aes(y = forecast), color = "blue") +
  labs(title = paste(symbol, "XGBoost Forecast vs. Actual (with Forecasted Exogenous)"),
       x = "Date", y = "Adjusted Price") +
  theme_minimal()
```


# Model 4: GARCH volatility model 
## Preparation for model 4
### Helper function
```{r}
# set outliers to quantile boundary (winsorization)
winsorize <- function(x, lower = 0.02, upper = 0.98) {
  qs <- quantile(x, probs = c(lower, upper), na.rm = TRUE)
  x[x < qs[1]] <- qs[1]
  x[x > qs[2]] <- qs[2]
  x
}

forecast_exog_garch <- function(train_df, test_df, var_name, freq = 252) {
  train_series <- as.numeric(train_df[[var_name]])
  train_series <- winsorize(train_series, lower = 0.1, upper = 0.9)
  h <- nrow(test_df)
  
  # Specify a simple GARCH(1,1) model with a constant mean
  spec <- ugarchspec(
    variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),
    distribution.model = "norm"
  )
  
  fit <- ugarchfit(spec = spec, data = train_series, solver = "hybrid")
  fc <- ugarchforecast(fit, n.ahead = h)
  
  # Extract the one-step-ahead point forecasts from the conditional mean
  forecast_mean <- fc@forecast$seriesFor
  list(
    forecast = as.numeric(forecast_mean)
  )
}
```

Sometimes GARCH fails to converge due to outliers, so we use the helper function `winsorize` to handle outliers.

### Forecast Exogenous Variables
```{r}
# GARCH requires more data, use daily data first
train_data <- df_stock %>%
  filter(date >= begin_date & date <= cutoff_date) %>%
  drop_na(adjusted_diff, volume_diff, rsi14_diff, ma20_diff, ma50_diff)

test_data <- df_stock %>%
  filter(date > cutoff_date) %>%
  drop_na(adjusted_diff, volume_diff, rsi14_diff, ma20_diff, ma50_diff)


exog_vars <- c("volume_diff", "rsi14_diff", "ma20_diff", "ma50_diff")
exog_forecasts_garch <- list()

for (var in exog_vars) {
  fc_res <- forecast_exog_garch(train_data, test_data, var, freq = 52)
  exog_forecasts_garch[[var]] <- fc_res$forecast
  cat("GARCH forecast for", var, ":", head(fc_res$forecast), "\n")
}

```

## Build Model 4
```{r}
train_ts_diff <- ts(train_data$adjusted_diff, frequency = 252)
xreg_train_diff <- as.matrix(train_data %>% 
                               select(volume_diff, rsi14_diff, ma20_diff, ma50_diff))

# For the test set, use the GARCH forecasts for exogenous regressors:
xreg_test_diff <- cbind(
  volume_diff = exog_forecasts_garch[["volume_diff"]],
  rsi14_diff  = exog_forecasts_garch[["rsi14_diff"]],
  ma20_diff   = exog_forecasts_garch[["ma20_diff"]],
  ma50_diff   = exog_forecasts_garch[["ma50_diff"]]
)

# Specify an ARIMAX-GARCH model using rugarch.
# Here, the mean model is ARIMA(0,0,0) with external regressors (we let the data decide further orders),
# and the variance is modeled with a GARCH(1,1) process.
spec_final <- ugarchspec(
  variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
  mean.model = list(armaOrder = c(0, 0), external.regressors = xreg_train_diff, include.mean = TRUE),
  distribution.model = "norm"
)

fit_final <- ugarchfit(spec = spec_final, data = train_ts_diff, solver = "hybrid")
summary(fit_final)

# forecast
h <- nrow(test_data)
fc_final <- ugarchforecast(fit_final, n.ahead = h, n.roll = 0,
                           external.forecasts = list(external.regressors = xreg_test_diff))
# Extract forecasted differences from the conditional mean
final_forecast_diff <- fc_final@forecast$seriesFor
```

## Performance
```{r}
last_train_level <- last(df_stock %>% filter(date <= cutoff_date) %>% pull(adjusted))
recovered_forecast <- last_train_level + cumsum(final_forecast_diff)

# Convert actual test levels to a time series (for plotting/evaluation)
test_ts_levels <- ts(test_data$adjusted, frequency = 252, 
                      start = c(1, length(train_data$adjusted) + 1))

df_plot <- tibble(
  date = test_data$date,
  actual = test_ts_levels,
  forecast = recovered_forecast
)

ggplot(df_plot, aes(x = date)) +
  geom_line(aes(y = actual), color = "black") +
  geom_line(aes(y = forecast), color = "blue") +
  labs(title = paste(symbol, "Recovered ARIMAX-GARCH Forecast vs. Actual (Levels)"),
       x = "Date", y = "Adjusted Price") +
  theme_minimal()

mape_final <- mean(abs(recovered_forecast - test_ts_levels) / abs(test_ts_levels)) * 100
mse_final  <- mean((recovered_forecast - test_ts_levels)^2)
cat("Final ARIMAX-GARCH Forecast -> MAPE:", round(mape_final, 2), "%, MSE:", round(mse_final, 2), "\n")

```

```{r}
checkresiduals(fit_final)
```

